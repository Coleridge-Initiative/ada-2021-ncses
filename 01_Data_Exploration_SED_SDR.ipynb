{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"450\">\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span> \n",
    "    <br>\n",
    "    \n",
    "# SED/SDR Dataset Exploration\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center>Maryah Garner, Ekaterina Levitskaya, Allison Nunez, Ben Feder, Rukhshan Arif Mian.</center>\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "This notebook gives the opportunity to spend some hands-on time with SED and SDR data. The notebook demonstrates various techniques on how to use SQL and R to explore these datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Setup\n",
    "\n",
    "Before using R functions that are not available in `base` R, load them using the built-in function `library()`. For example, running `library(tidyverse)` loads the `tidyverse` suite of packages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this notebook, we run it slightly differently – you may execute the cell below to load in the libraries. We utilize the `suppressMessages` and `options` functions to reduce clutter in our output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching off warnings\n",
    "options(warn = -1)\n",
    "\n",
    "# Database interaction imports\n",
    "suppressMessages(library(odbc))\n",
    "\n",
    "# for data manipulation/visualization\n",
    "suppressMessages(library(tidyverse))\n",
    "\n",
    "# scaling data, calculating percentages, overriding default graphing\n",
    "suppressMessages(library(scales))\n",
    "\n",
    "# add weights to data\n",
    "suppressMessages(library(survey))\n",
    "\n",
    "#Switching on warnings\n",
    "options(warn = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of `suppressMessages` is to hide all messages associated with reading in a library and we use `options(warn = -1)` to switch off warnings. These two functions do not impact our results in any way but serve to reduce clutter in our output. `options(warn = 0)` is used to switch on the warnings as we do not want to ignore any future warnings in our code but only the ones associated with reading in the libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for loading the libaries without surpressing the warnings is as follows:\n",
    "\n",
    "```\n",
    "# database interaction imports\n",
    "library(odbc)\n",
    "\n",
    "# for data manipulation/visualization\n",
    "library(tidyverse)\n",
    "\n",
    "# scaling data, calculating percentages, overriding default graphing\n",
    "library(scales)\n",
    "\n",
    "# add weights to data\n",
    "library(survey)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish a Connection to the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a connection to the database using the `dbConnect` function. The `Driver` argument is specifying the type of SQL database, while the `Server` arguments points to where the database is within the ADRF. \n",
    "\n",
    "When creating a new notebook in this course, make sure to copy the following code chunk to be able to connect to the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Database Connection__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "con <- DBI::dbConnect(odbc::odbc(),\n",
    "                     Driver = \"SQL Server\",\n",
    "                     Server = \"msssql01.c7bdq4o2yhxo.us-gov-west-1.rds.amazonaws.com\",\n",
    "                     Trusted_Connection = \"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulate Data Query\n",
    "\n",
    "This part is similar to writing a SQL query in DBeaver. Depending on the questions of interest, different queries can be used to pull different data. In this example, the query below is used to pull all columns from the SED data for doctoral students who graduated in 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query character string\n",
    "    # Database name: ds_nsf_ncses\n",
    "    # Schema name: dbo\n",
    "    # Table name: nsf_sed\n",
    "\n",
    "query <- \"\n",
    "SELECT TOP 10 *\n",
    "FROM ds_nsf_ncses.dbo.nsf_sed\n",
    "WHERE phdfy = '2015'\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `SELECT TOP` is used to read-in only the first 10 rows - this is just a preview of the data, and it also allows to avoid eating up memory by reading a large data frame into R. \n",
    "\n",
    "> `SELECT TOP` provides one simple way to get a \"sample\" of data; however, using `TOP` does **not provide a _random_** sample. It may return different samples of data, but it is just based on what is fastest for the database to return.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the Data \n",
    "\n",
    "Now the data can be read into an R data frame using the `con` and `query` as inputs to `dbGetQuery()`. \n",
    "\n",
    "> Recall that `con` (our server connection) includes a reference that tells it what driver to use. Forgetting to set up the driver would cause an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into an R dataframe called df\n",
    "df <- dbGetQuery(con, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see first 5 rows of df\n",
    "head(df,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "This section covers aggregating statistics on the data. The goal of this exercise is to get a better understanding of the data. Ask the following questions: Are the data generally clean? What are possible sources of error? What are the types of objects and what are the variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: __Large tables__ can take a long time to process on shared databases, so using SQL and R is demonstrated with consideration for how much data is read back into R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer these broader research questions, start by looking at simple aggregate statistics in each of the data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration #1: **Survey of Earned Doctorates (SED)**\n",
    "\n",
    "**Motivating Questions:**\n",
    "- What are the most pursued fields of study by doctorate students?\n",
    "- What are the most common sources of funding?\n",
    "\n",
    "In order to avoid pulling a large amount of information, only pull in the data with the unique identifier of a person (**drf_id**) and their field of study (in the SED data this variable is called **PHDFIELD_NAME**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field of Study\n",
    "\n",
    "In this sub-section, we explore the counts for different fields of study within the SED data. For this purpose, we first take a look at the data dictionary to identify the variable associated with field of study. In this case, the relevant variable is: **PHDFIELD_NAME**. We then use SQL to aggregate counts by each **PHDFIELD_NAME**.\n",
    "\n",
    "It is important to note that because we are using confidential data in this class that needs to be submitted for export before it can be shared publicly, every produced statistic that has a count of individuals also needs to have a related count of institutions. According to the NCSES/IRIS export rules, only those statistics that have more than 10 individuals from at least 3 institutions could be disclosed publicly. Therefore, we will add two variables: **indiv_count** (count of individuals) and **inst_count** (count of institutions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query character string\n",
    "    # Database name: ds_nsf_ncses\n",
    "    # Schema name: dbo\n",
    "    # Table name: nsf_sed\n",
    "\n",
    "qry = \"\n",
    "SELECT PHDFIELD_NAME, COUNT(DISTINCT(drf_id)) as indiv_count, COUNT(DISTINCT(phdinst)) as inst_count\n",
    "FROM ds_nsf_ncses.dbo.nsf_sed\n",
    "WHERE phdfy = '2015'\n",
    "GROUP BY PHDFIELD_NAME\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that we use `DISTINCT` within the `COUNT` function in our code above. This is done in order to make sure that we are counting unique (distinct) values of **drf_id** to avoid duplicated counts – we use `DISTINCT` here to avoid double counting individuals. We can also see that each group in this table represents more than 10 individuals from more than 3 institutions, therefore, this table would pass the disclosure review to be released publicly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into an R dataframe called sed_fos\n",
    "sed_fos <- dbGetQuery(con, qry)\n",
    "\n",
    "# View the entire sed_fos data frame\n",
    "sed_fos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate percentages for each field of study and arrange them in descending order.\n",
    "\n",
    "It’s important to note that since we are using confidential data that needs to be submitted for export prior to being shared publicly, every produced statistic will require the underlying count of individuals and the count of their associated unique institutions. Only those statistics produced using 10 or more individuals from at least 3 universities can be disclosed publicly. Further, counts and percentages need to be rounded. \n",
    "\n",
    "To calculate the percentage for the disclosure review process, we need to follow these steps:\n",
    "- **Step 1. Round the counts in both numerator and denominator**  (**indiv_count_rounded** and **total_count_rounded**). Both numerator and denominator (before rounding) need to have at least 10 individuals from at least 3 institutions.\n",
    "> According to the NCSES/IRIS rounding rules, numbers below 999 should be rounded to the nearest ten, and numbers above 999 should be rounded to the nearest hundred. \n",
    "> When using the `round` fundtion, rounding to a negative number of digits means rounding to a power of ten, so round(x, digits = -1) rounds to the nearest ten while round(x, digits = -2) rounds to the nearest hundred.\n",
    "When you do not specify the number of digits, the `round` function will round to the nearest whole number.\n",
    "- **Step 2. Calculate the percentage on the rounded counts** (**percentage**)\n",
    "- **Step 3. Round the percentage to the whole number** (**percentage_rounded**) - this would be the final percentage that could be released publicly, if the unrounded counts in the numerator and the denominator pass the threshold mentioned above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to show the evidence of both unrounded and rounded counts for the disclosure review process, so we will keep all these variables in the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed_fos <- sed_fos %>%\n",
    "# Create a new column for total individuals (it will repeat for each observation) \n",
    "    mutate(total_indiv = sum(indiv_count),    # use the sum function to add together all the indiv_count\n",
    "           indiv_count_rounded = case_when(indiv_count > 999 ~ round(indiv_count, digits = -2),  # round to the nearest 100\n",
    "                                           indiv_count < 999 ~ round(indiv_count, digits = -1)), # round to the nearest 10\n",
    "           total_indiv_rounded = case_when(total_indiv > 999 ~ round(total_indiv, digits = -2),  # round to the nearest 100\n",
    "                                           total_indiv < 999 ~ round(total_indiv, digits = -1)),  # round to the nearest 10\n",
    "           percentage = (indiv_count_rounded / total_indiv_rounded) * 100,                      # calculate percentage\n",
    "           percentage_rounded = round(percentage)) %>%                                          # round percent to the nearest whole number\n",
    "    arrange(desc(percentage))                                                                   # sort in decending order \n",
    "\n",
    "# View the entire sed_fos data frame\n",
    "sed_fos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source of Funding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we address the following question: What are the most common sources of funding?\n",
    "\n",
    "We start our data exploration by calling the relevant variable for sources of funding: **srceprim**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the query and select only two variables: unique identifier (drfid) and primary source of support (srceprim)\n",
    "    # Database name: ds_nsf_ncses\n",
    "    # Schema name: dbo\n",
    "    # Table name: nsf_sed\n",
    "\n",
    "query <- \"\n",
    "SELECT drf_id, srceprim\n",
    "FROM ds_nsf_ncses.dbo.nsf_sed\n",
    "WHERE phdfy = '2015'\n",
    "\"\n",
    "\n",
    "# Read the data into an R dataframe called sed_ncses_2015\n",
    "sed_ncses_2015 <- dbGetQuery(con, query)\n",
    "\n",
    "# View the first 6 rows of the table\n",
    "head(sed_ncses_2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `unique` function returns a vector, data frame or array like x but with duplicate elements/rows removed.\n",
    "Below we use the `unique` function to identify all of the values the variable **srceprim** takes on. \n",
    "- Since **srceprim** is a vector inside the **sed_ncses_2015** data frame, a vector of values is returned with all the the dublicates removed, (i.e. the unique values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check what are the unique values in the primary support variable (srceprim)\n",
    "unique(sed_ncses_2015$srceprim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the REDACTED observation listed above is an REDACTED REDACTED `REDACTED`. These observations are not coded as NA, rather they have an empty string for their recorded value. This is an important distinction we will have to make when recoding and grouping the Primary Source of funding below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `COUNT`, `GROUP BY` and `ORDER BY` functions in SQL to aggregate the number of graduates in each category and sort them in a descending order. As a reminder, we also need to add the counts of institutions for the disclosure review process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of graduates (their distince drf_id), \n",
    "# group by a primary source of support variable, \n",
    "# sort the counts in a descending order\n",
    "query <- \"\n",
    "SELECT srceprim, COUNT(DISTINCT(drf_id)) AS indiv_count, COUNT(DISTINCT(phdinst)) AS inst_count\n",
    "FROM ds_nsf_ncses.dbo.nsf_sed\n",
    "WHERE phdfy = '2015'\n",
    "GROUP BY srceprim\n",
    "ORDER BY indiv_count DESC\n",
    "\"\n",
    "\n",
    "# Read the data into an R dataframe called primary_support\n",
    "primary_support <- dbGetQuery(con, query)\n",
    "\n",
    "# View the results (i.e. the entire dataframe)\n",
    "primary_support  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Primary Source categories\n",
    "We have arrived at the most common sources of funding but at this point, it is unclear what each row refers to. That is, we are not sure what source of funding refers to 'A', 'B' or any of the remaining categories. In order to address this, we utilize SED's data dictionary through which we can look up categories and recode our values based on those. We utilize `case_when` to approach this. \n",
    "\n",
    "The data dictionary can be found here: `tr-ncses-2021\\Documentation\\2017 SED Codebook.docx`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recoding – Part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_support <- primary_support %>% \n",
    "    mutate(source_name=case_when(\n",
    "                        srceprim == \"A\" ~ \"Fellowship, scholarship\",\n",
    "                        srceprim == \"B\" ~ \"Dissertation grant\",\n",
    "                        srceprim == \"C\" ~ \"Teaching assistantship\",\n",
    "                        srceprim == \"D\" ~ \"Research assistantship\",\n",
    "                        srceprim == \"E\" ~ \"Other assistantship\",\n",
    "                        srceprim == \"F\" ~ \"Traineeship\",\n",
    "                        srceprim == \"G\" ~ \"Internship, clinical residency\",\n",
    "                        srceprim == \"H\" ~ \"Loans (from any source)\",\n",
    "                        srceprim == \"I\" ~ \"Personal savings\",\n",
    "                        srceprim == \"J\" ~ \"Personal earnings during graduate school (other than sources listed above)\",\n",
    "                        srceprim == \"K\" ~ \"Spouse's, partner's, or family's earnings or savings\",\n",
    "                        srceprim == \"L\" ~ \"Employer reimbursement/assistance\",\n",
    "                        srceprim == \"M\" ~ \"Foreign (non-U.S.) support\",\n",
    "                        srceprim == \"\" ~ \"Unknown\",\n",
    "                        srceprim == \"N\" ~ \"Other - specify\"))\n",
    "\n",
    "# View the first 6 rows of the data frame\n",
    "head(primary_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recoding Part 2 – Creating a broader category:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will group the 15 sources of funding into the 6 broader categories listed below. \n",
    "For your own research project, there are a few different reasons you might want to group specific outcomes into broader categories; for instance, you might want to connect the three main data sources together (SED,SDR and UMETRICS) for your final analysis, and you might not have sufficient coverage to analyze the more nuanced differences in funding sources or over variables of interest.\n",
    "\n",
    "1. Fellowship\n",
    "2. Research Assistantship (RA)\n",
    "3. Teaching Assistantship (TA)\n",
    "4. Loan/Personal\n",
    "5. Other\n",
    "6. Unknown\n",
    "\n",
    "We used these 6 categories because the literature supports using these categories.  \n",
    "\n",
    "Use the `==` operator when identifying is **srceprim** takes on a spacific value (i.e. srceprim == \"C\") and the `%in%` operator we when identifying is srceprim takes on one of several values (i.e. %in% c(\"H\", \"I\", \"J\")). \n",
    "- In the later example (srceprim %in% c(\"H\", \"I\", \"J\") ~ \"Own Funds/Loan\") if **srceprim** takes on either \"H\", \"I\", or \"J\", **source_cat** will be assigned the value \"Own Funds/Loan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mutate and case_when, create a new variable called source_cat\n",
    "primary_support <- primary_support %>% \n",
    "   mutate(source_cat = case_when(srceprim %in% c(\"A\", \"B\") ~ \"Fellowship Grant\",\n",
    "                                  srceprim == \"C\" ~ \"Teaching \\nAssistantship\", \n",
    "                                  srceprim == \"D\" ~ \"Research \\nAssistantship\",\n",
    "                                  srceprim %in% c(\"H\", \"I\", \"J\") ~ \"Own Funds/Loan\", \n",
    "                                  srceprim %in% c(\"E\", \"F\", \"G\", \"K\", \"L\", \"M\",\"N\") ~ \"Other\",\n",
    "                                  srceprim == '' ~ 'Unknown'))\n",
    "\n",
    "# View entire primary_support dataframe\n",
    "primary_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration #2: **Survey of Doctorate Recipients (SDR)**\n",
    "\n",
    "**Motivating Question:** What is the distribution of earnings by gender? You will look at race/ethinicity in the checkpoints notebook.\n",
    "\n",
    "As the SDR data includes sub-samples of the SED population, survey weights need to be used in the calculations. Applying survey weights allows us to take into account an unequal sample selection – we do these to make the statistics we compute to be more representative of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of earnings by gender \n",
    "Find the distribution of earnings from the  2017 SDR for the cohort 2015.\n",
    ">  use the variable **sdryr** (the year of first award of a U.S. PhD degree) to subset the data for the 2015 cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the query and select only 4 variables: refid (the unique identifier), gender, salary, wtsurvy (serve weights)\n",
    "    # Database name: ds_nsf_ncses\n",
    "    # Schema name: dbo\n",
    "    # Table name: sdr_2017\n",
    "    # subset: 2015 cohort\n",
    "query <- \"\n",
    "SELECT refid, gender, salary, wtsurvy \n",
    "FROM ds_nsf_ncses.dbo.sdr_2017\n",
    "WHERE sdryr = '2015'\n",
    "\"\n",
    "\n",
    "# Read the data into an R dataframe called gender_earnings\n",
    "gender_earnings <- dbGetQuery(con, query)\n",
    "\n",
    "#View the first 6 rows of the data frame\n",
    "head(gender_earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we observe how values for certain salaries do not make sense. These are referred to as logical skips – defined by Qualtrics, a renowned survey platform, as:\n",
    "\n",
    "*Skip logic allows you to send respondents to a future point in the survey based on how they answer a question. For instance, if a respondent indicates that they don’t agree to your survey’s consent form, they could immediately be skipped to the end of the survey.*\n",
    "\n",
    "For the purpose of our data exploration tasks, we remove any salaries associated with logical skips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all observarions with a recorded salery of 9999998\n",
    "gender_earnings <- gender_earnings[gender_earnings$salary != 9999998, ]\n",
    "\n",
    "#View the first 6 rows of the data frame\n",
    "head(gender_earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying weights\n",
    "When loading the R libraries at the beginning of the notebook, an R package called `survey` was imported (by calling `library(survey)`). This library allows to calculate weighted variables by applying survey weights to the data.\n",
    "\n",
    "Apply a `svydesign` function to the unweighted data frame called `gender_earnings`, to calculate the weighted earnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_earnings_weighted <- svydesign(ids=~1, data=gender_earnings, weights=gender_earnings$wtsurvy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a data frame, the `svydesign` function returns an object of class `survey.design` - try to call `gender_earnings_weighted`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_earnings_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not a regular table output, like with data frames. For this new object, use functions provided in the survey package. For example, to find a weighted mean of female earnings, call a function called svymean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted mean by group (gender)\n",
    "\n",
    "Since we are hoping to look at the mean of **salary** by each **gender**, we combine two functions: `svyby` and `svymean`. The code syntax will be as follows:\n",
    "\n",
    "```\n",
    "svby(~var_to_calc_mean_for, ~var_to_group_by, weighted_df_name, svymean, keep.names=FALSE)\n",
    "```\n",
    "\n",
    "For our implementation, the associated variables would be:\n",
    "\n",
    "- var_to_calc_mean_for: **salary**\n",
    "- var_to_group_by: **gender**\n",
    "- weighted_df_name: **gender_earnings_weighted**\n",
    "- keep.names: This is always equal to FALSE in our case\n",
    "\n",
    "The implementation is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_earnings_by_gender <- svyby(~salary, ~gender, gender_earnings_weighted, svymean, keep.names = TRUE)\n",
    "weighted_earnings_by_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unweighted mean by group (gender)\n",
    "\n",
    "Compare the weighted mean with the unweighted mean for each gender (using the unweighted data frame called `gender_earnings`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_earnings_by_gender <- gender_earnings %>%\n",
    "    group_by(gender) %>%\n",
    "    summarise_at(vars(salary), list(mean=mean), na.rm=TRUE)\n",
    "\n",
    "unweighted_earnings_by_gender "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight difference between unweighted and weighted means - remember, with the survey data, always use the weighted variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Results\n",
    "\n",
    "We have already created a directory structure for you. Within the `Module 2` folder, you will see the following:\n",
    "\n",
    "- Figures\n",
    "- Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now save some of the tables that we created above as csv files.\n",
    "\n",
    "For this purpose, we utilize the following code:\n",
    "\n",
    "`write.csv(df_to_save, \"Tables\\\\df_to_save.csv\", row.names = FALSE)`\n",
    "\n",
    "Here:\n",
    "\n",
    "- `df_to_save` refers to the R dataframe we want to save. \n",
    "- `\"Tables\\\\df_to_save.csv\"` refers to the filepath, we would like to save our dataframe in.\n",
    "- `row.names = FALSE` excludes row numbers when we save our dataframe as a csv. If we had `TRUE` instead of `FALSE`, we would have an extra column (of row numbers) as the first column in our csv. \n",
    "\n",
    "\n",
    "We have added the saving code for each dataframe we want to save and you do not have to make any updates to the code below in order for it to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary source of support\n",
    "write.csv(primary_support, \"Tables\\\\primary_support_coverage.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing the Database connection\n",
    "\n",
    "Uncomment the code below to close the database connection. This allows us to free up resources (most importantly, memory) for future work. However, you are advised to close the connection only when you have executed the cells above. \n",
    "\n",
    "**Note**: Once the connection is closed, you will have to re-open the connection (at the start of the notebook) to utilize run the code again. You will not be able to run any SQL-related code in R once the connection is closed. That is, once you have run `dbDisconnect(con)`, you will have to re-run the code associated with establishing a connection with SQL to interact with any tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "# dbDisconnect(con)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "566px",
    "left": "0px",
    "right": "954px",
    "top": "110px",
    "width": "179px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
