{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation Prep\n",
    "\n",
    "Maryah Garner, Benjamin Feder, Nathan Caplan,  Brian Kim, Ekaterina Levitskaya, Allison Nunez, Rukhshan Arif Mian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Presentation Prep Examples & Exercises_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides information on how to prepare research output for disclosure control. It outlines how to prepare different kind of outputs before submitting an export request and gives an overview of the information needed for disclosure review. _Please read through the entire notebook because it will separately discuss all outputs that will be flagged in the disclosure review process._\n",
    "\n",
    "\n",
    "For the purpose of this class, the disclosure rules are as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCSES 2021 Class Export Review Guidelines \n",
    "\n",
    "- **Each team will be able to export up to 7 figures**\n",
    "    -Teams will not be allowed to export summary data tables to create figures outside the ADRF\n",
    "    \n",
    "- **Every statistic for export should be based on at least 10 individuas and at least 3 institutions**.\n",
    "     - This includes statistics that are baised off 0-9 individuals must be surpressed\n",
    "- **All counts will need to be rounded** \n",
    "    - Numbers below 999 should be rounded to the nearest ten, and numbers above 999 should be rounded to the nearest hundred.  \n",
    "    \n",
    "- **All percentages and proportions need to be rounded**\n",
    "    - The same rounding rule that is applied to counts must be applied to both the numerator and denominator, then percentages must be rounded to the nearest percent, and proportions must be rounded to the nearest hundredth.\n",
    "\n",
    "- **Exact percentiles can not be exported** \n",
    "    - Instead, for example, you may calculate a “fuzzy median,” by averaging the true 45th and 55th percentiles. We illustrated an example of this in the `01_Data_Exploration_SED_SDR.ipynb` notebook in Module 2 as well – we do go over this in more detail in this notebook. \n",
    "  \n",
    "- **Exact Maxima and Minima can not be exported**\n",
    "    - Suppress maximum and minimum values in general. You may replace an exact maximum or minimum with a top-coded value or a .\n",
    " \n",
    "- **Complementary suppression**\n",
    "    - If your figures includes totals or are dependent on a preceding or subsequent figures, you need to take into account complementary disclosure risks—that is, whether the figure’ totals, or the separate figures when read together, might disclose information about less then 10 individuals in the data in a way that a single, simpler table would not. Team facilitators and export reviewers will work with you by offering guidance on implementing any necessary complementary suppression techniques.\n",
    " \n",
    "- **Text Analysis**\n",
    "    - To export figures for text analysis, the same rules apply. So you will have to recover the number of individuals and the number of institutions that are behind the figures you are exporting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Supporting documentation for exports\n",
    "\n",
    "For each exported figure, you will need to provide a table with **underline counts** of individuals and institutions for each statistic depicted in the figure. \n",
    "\n",
    "- You will need to include both the rounded and the unrounded counts of individuals.\n",
    "\n",
    "- If percentages or proportions are to be exported, you must report both the rounded and the unrounded counts of individuals for the numerator and denominator. You must also report the counts of institutions for both the numerator and the denominator\n",
    "\n",
    "- If weighted results are to be exported, you must report both weighted and unweighted individual counts as well as institution counts (you do not need to report weighted institution counts).\n",
    "\n",
    "**Text Analysis**\n",
    "- If you are exporting figures for text analysis on grants, you must report counts of individuals for each `term`. Counts should include the intended population of the figure which may be less them all the individuals on each grant. \n",
    "    - Ex. If you are using text analysis to say something about PhD graduates from 2015, you must report the counts for the PhD graduates from 2015, even if other people are on the grants. \n",
    "    \n",
    "**Code**\n",
    "- Please provide the code for every output that needs to be exported. It is important for the ADRF staff to have the code to better understand what exactly was done. Understanding how research results are created is important in understanding the research output. Thus, it is important to document every step of the analysis in the Jupyter notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General rules to keep in mind\n",
    "A more detailed description of the rules for exporting results can be found in the [export documentation](https://coleridgeinitiative.org/adrf/documentation/using-the-adrf/exporting-results/). Before preparing an export submission, please read through the export documentation. The overall guidelines are:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switching off warnings\n",
    "options(warn=-1)\n",
    "\n",
    "#database interaction imports\n",
    "suppressMessages(library(odbc))\n",
    "\n",
    "# for data manipulation/visualization\n",
    "suppressMessages(library(tidyverse))\n",
    "\n",
    "# scaling data, calculating percentages, overriding default graphing\n",
    "suppressMessages(library(scales))\n",
    "\n",
    "# adding weights \n",
    "suppressMessages(library(survey))\n",
    "\n",
    "# to better view images\n",
    "# For easier viewing of graphs\n",
    "# Adjust repr.plot.width and repr.plot.height to change the size of graphs\n",
    "theme_set(theme_gray(base_size = 24))\n",
    "options(repr.plot.width = 20, repr.plot.height = 12)\n",
    "options(warn=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an additional option for this notebook:\n",
    "\n",
    "- `options(scipen = 100)`prevents R from using scientific notation when plotting or printing numbers. An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before implementation\n",
    "print(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing option\n",
    "options(scipen = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after implementation\n",
    "print(100000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we connect to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "con <- DBI::dbConnect(odbc::odbc(),\n",
    "                     Driver = \"SQL Server\",\n",
    "                     Server = \"msssql01.c7bdq4o2yhxo.us-gov-west-1.rds.amazonaws.com\",\n",
    "                     Trusted_Connection = \"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation: Comparing female earnings to male earnings across the 2015 cohort\n",
    "\n",
    "The motivating question for this notebook is to look at how female earnings compare to male earnings for doctorate students who graduated in 2015. We address this question through multiple steps. Furthermore, this notebook describes how to construct useful statistics and visualizations using the class data and how to prepare them so that they can be approved as output during the export process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, we retrieve the necessary data for this notebook. We will be using the SDR table and the relevant variables are: \n",
    "- earnings (`salary`)\n",
    "- survey weight (`wtsurvy`) - the data in the SDR needs to be weighted, as it is a subsample of a population\n",
    "- individual ID (`refid`)\n",
    "- institution ID (`sdrincd`)\n",
    "- year of graduation (`sdr`) - where year is 2015\n",
    "- gender (`gender`) – Male or Female\n",
    "    - In this case, we are using 2 categories for gender (Male/Female) even though this is not necessary. There are no other categories that can be used as these are the options that SDR respondents are presented with when the survey is conducted. \n",
    "    \n",
    "> Note: Whenever pulling statistics, remember to include individual and institution information, as they will be required to check if the statistics in question pass the disclosure threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the relevant variables from the SDR data and save in the earnings data frame: \n",
    "# - earnings (salary),\n",
    "# - survey weight (wtsurvy),\n",
    "# - individual ID (refid),\n",
    "# - institution ID (sdrincd),\n",
    "# - where year of graduation (sdryr) is 2015\n",
    "\n",
    "query <- \"\n",
    "SELECT salary, wtsurvy, refid, sdrincd, gender\n",
    "FROM ds_nsf_ncses.dbo.nsf_sdr_2017\n",
    "WHERE sdryr = '2015' \n",
    "\"\n",
    "earnings <- dbGetQuery(con,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few rows of the table\n",
    "head(earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that as per the Survey of Doctorate Recipients' (SDR) data dictionary, `salary` values equal to `9999998` are reserved for 'Logical Skips'. Therefore, these values can be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with logical skip values\n",
    "earnings <- earnings[earnings$salary != '9999998', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For filtering these logical skips using using the tidyverse, the code would be `earnings <- earnings %>% filter(salary != '9999998')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regrouping Data\n",
    "In our data exploration notebooks in Module 2, we worked on creating broader categories from categorical variables. This sub-section focuses on using the same methods but on a different variable type (continuous).\n",
    "\n",
    "The column we choose to regroup is **salary**. Remember that we are using the SDR table and it requires us to utilize survey weights for any summary statistics. Since we are not performing any such analysis and are just regrouping, we move forward without using survey weights. \n",
    "\n",
    "A suggested regrouping is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings <- earnings %>%\n",
    "                    mutate(salary_range = case_when(salary >= 0 & salary <= 50000 ~ '0 - 50K',\n",
    "                                                    salary >= 50000 & salary <= 100000 ~ '50K - 100K',\n",
    "                                                    salary >= 100000 & salary <= 500000 ~ '100K - 500K',\n",
    "                                                    salary >= 500000 & salary <= 1000000 ~ '500K - 1M',\n",
    "                                                    salary >= 1000000 & salary <= 5000000 ~ '1M - 5M'\n",
    "                                                ))\n",
    "\n",
    "all_counts <- earnings %>% \n",
    "                         group_by(salary_range) %>% # grouping by salary range\n",
    "                        summarise(individual_count = n_distinct(refid), # get counts of individuals\n",
    "                                 institution_count = n_distinct(sdrincd)) # get counts of institutions\n",
    "\n",
    "all_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we observe that two categories, *500K-1M* and *1M-5M* have an individual count or institution count (or both) that does not meet our disclosure review criteria. To move forward, we do the following: \n",
    "\n",
    "1. Drop these two categories (as these are outliers) \n",
    "2. Use a different type of grouping that takes these higher values into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings <- earnings %>% \n",
    "    filter(salary_range != '500K - 1M', salary_range != '1M - 5M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with mutate, `salary_range_new', with the new bin ranges defined above\n",
    "earnings <- earnings %>%\n",
    "                    mutate(salary_range_new = case_when(salary >= 0 & salary <= 30000 ~ '0 - 30K',\n",
    "                                                    salary >= 30000 & salary <= 60000 ~ '30K - 60K',\n",
    "                                                    salary >= 60000 & salary <= 90000 ~ '60K - 90K',\n",
    "                                                    salary >= 90000 & salary <= 100000 ~ '90K - 100K',\n",
    "                                                    salary >= 100000 & salary <= 150000 ~ '100K - 150K',\n",
    "                                                    salary >= 150000 & salary <= 180000 ~ '150K - 180K',\n",
    "                                                    salary >= 180000 ~ '180K+',\n",
    "                                                ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how this codes any salary greater than 180K in one single category. We check the associated individual and institution counts below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts <- earnings %>% \n",
    "                        group_by(salary_range_new) %>%\n",
    "                        summarise(indiv_count = n_distinct(refid), # individual counts\n",
    "                                  inst_count = n_distinct(sdrincd) # institution counts\n",
    ")\n",
    "\n",
    "all_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all salary categories meet our disclosure review requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the underlying counts\n",
    "all_counts %>%\n",
    "    write_csv(\"Tables\\\\counts_for_unweighted_hist_earnings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question for this notebook focuses on comparing male earnings to female earnings. We consider using a bar plot to do so by looking at the **percentage of males/females who fall in a certain salary range.** (that we created above).\n",
    "\n",
    "\n",
    "In `01_SED_SDR_Data_Exploration.ipynb`, we looked at the best practices for looking at percentages. We provide a brief recap below:\n",
    "\n",
    "When working with percentages (both numerically and visually), it is important to show the underlying numerator and denominator counts. The following are the rules for calculating any percentages/proportions/ratios:\n",
    "- Calculate percentages, proportions, and ratios using the unweighted counts.\n",
    "- The numerator and denominator should be above the threshold for each group, or bar, specified in the disclosure review (in this class, at least 10 individuals and at least 3 institutions).\n",
    "- Round percentages calculated from unweighted counts to 1 decimal.\n",
    "- Do not report 0 and 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted counts\n",
    "Within SDR, each weight represents a certain number of individuals, so to find the weighted counts within each group (bar), the `wtsurvy` variable can be summed by the **salary_range_new-gender** grouping as long as each individual only has one observation in the data frame. We will check this below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicates\n",
    "earnings %>%\n",
    "    group_by(refid) %>% # grouping by unique ID\n",
    "    mutate(count = n()) %>% # counting the number of instances\n",
    "    arrange(desc(count)) %>% # ordering by count\n",
    "    head() # checking first few observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating underlying counts\n",
    "earnings_prop <- earnings %>%\n",
    "    group_by(gender, salary_range_new) %>%  # for each number of semesters\n",
    "    summarise(count_individuals = n_distinct(refid), # counting the number of individuals\n",
    "              count_institutions = n_distinct(sdrincd), # counting the number of institutions\n",
    "              count_individuals_weighted = sum(wtsurvy)) %>% # getting the weighted counts of individuals\n",
    "    mutate(total_individuals = sum(count_individuals)) %>%                   # get the total count of unique individuals\n",
    "    mutate(percent = round((count_individuals/total_individuals) * 100, 1))  # find the percentage and round to 1 decimal (not necessary but nice to see)\n",
    "\n",
    "earnings_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the underlying counts (numerator and denominator) for the bars are not directly evident on the visualization, they must be included in the export request as supplemental information in a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse our code from the `05_Data_Visualization.ipynb` notebook in Module 2 to create a Bar Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color-blind friendly palette\n",
    "cbPalette <- c( \"#009E73\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#999999\", \"#E69F00\",  \"#56B4E9\", \"#F0E442\")\n",
    "\n",
    "bar_plot <- earnings_prop %>%\n",
    "    ggplot(aes(x=salary_range_new, y=percent, fill=gender)) +\n",
    "    geom_bar(stat=\"identity\", position='dodge') +\n",
    "    scale_x_discrete(limits = c('0 - 30K', '30K - 60K', '60K - 90K', '90K - 100K', \n",
    "                                '100K - 150K', '150K - 180K', '180K+')) +\n",
    "    scale_fill_manual(values = cbPalette) +\n",
    "    labs(\n",
    "        x = 'Salary Range', # labelling x axis\n",
    "        y = '% of individuals', # labelling y axis\n",
    "        title = 'Females who graduated in 2015 earn a REDACTED salary on average compared to Males', # adding title\n",
    "        caption = 'NCSES SDR 2017 Data (2015 graduates)' # adding a caption\n",
    "        )\n",
    "\n",
    "bar_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Font Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make our plot presentation ready, it is always advised to use readable font sizes. We use the following code to implement this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot <- bar_plot + theme(\n",
    "        legend.text = element_text(size=24), # legend text font size\n",
    "        legend.title = element_text(size=24), # legend title font size\n",
    "        axis.text.x = element_text(size=24), # x axis label font size\n",
    "        axis.title.x = element_text(size=24), # x axis title font size\n",
    "        axis.text.y = element_text(size=24), # y axis label font size\n",
    "        axis.title.y = element_text(size=24) # y axis title font size\n",
    "    )\n",
    "    \n",
    "bar_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please keep in mind that any statistics (e.g. for counts of subpopulations) have to comply with the disclosure threshold described above -  not only the **counts of individuals** (**more than 10**), but also the **counts of institutions** (**more than 3**). Additionally, in cases where weights are involved, we have to export weighted counts as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts <- earnings_prop %>% \n",
    "        select(c(\"gender\", \"salary_range_new\", \"count_individuals\", \"count_institutions\", \"count_individuals_weighted\"))\n",
    "\n",
    "all_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the underlying counts\n",
    "all_counts %>%\n",
    "    write_csv(\"Tables\\\\counts_for_weighted_bar_earnings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we delve into understanding the the distribution of female earnings compared to male earnings across the 2015 cohort. For this purpose, we utilize fuzzy percentiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinarily, when simply finding the distribution of a numerical variable, the `summary()` function may be used. As a reminder, this function outputs the minimum, first quartile, median, mean, third quartile, and maximum values as per its default output. However, these outputs will not pass the disclosure review process, as some of these statistics may be represented by individual points (such as minimum, maximum, any percentiles, and median). \n",
    "\n",
    "Instead, these outputs can be transformed into _fuzzy percentiles_, which can pass the disclosure review process. For example, the 20th and 30th percentiles can be averaged to find a fuzzy 25th percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As done in the Data Exploration notebook, the survey weights can now be added using `svydesign` function from `survey` package to calculate the weighted earnings distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weights using \"svydesign\" function from \"survey\" library\n",
    "earnings_weighted <- svydesign(ids=~1, data=earnings, weights=earnings$wtsurvy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, to export the 25th, 50th, and 75th percentiles, they need to be transformed into fuzzy percentiles by averaging close-by percentiles. For example, in order to find a fuzzy 25th percentile, the 20th and 30th percentiles can be averaged.\n",
    "\n",
    "Start by finding the following true percentiles on the weighted data using `svyquantile`:\n",
    "- 20th and 30th (to create a fuzzy 25th percentile),\n",
    "- 45th and 55th (to create a fuzzy 50th percentile),\n",
    "- 70th and 80th percentile (to create a fuzzy 75th percentile). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 20, 30, 45, 55, 70, 80 percentiles on the weighted data\n",
    "svyquantile(~salary, earnings_weighted, c(.20, .30, .45, .55, .70, .80), na.rm=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_by_gender <- svyby(~salary, ~gender, earnings_weighted, svyquantile, quantiles=c(.20, .30, .45, .55, .70, .80), na.rm=TRUE, keep.var=FALSE, keep.names=FALSE)\n",
    "names(weighted_by_gender) = c(\"gender\", .20, .30, .45, .55, .70, .80)\n",
    "\n",
    "weighted_by_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: It is not best practice to save column names as numerical outputs. The code below will show how to work with these types of columns. After creating the data frame, the default column names can be overwritten by manually assigning the desired column names with the base code <br> `colnames(dataframe) <- c('changed', 'column', 'names')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find 20, 30, 45, 55, 70, 80 percentiles on the weighted data and save results to a dataframe\n",
    "true <- weighted_by_gender\n",
    "names(true) <- c('gender', 'Q.20', 'Q.30', 'Q.45', 'Q.55', 'Q.70', 'Q.80')\n",
    "true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the column names of `true` dataframe are to be left as numbers, these columns can be referenced by surrounding them in backticks. These percentiles can be averaged to find fuzzy 25th, 50th (median), and 75th percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find values for the fuzzy quantiles by averaging the percentiles \n",
    "# (e.g. to find 25th, average 20th and 30th, etc.)\n",
    "weighted_by_gender %>%\n",
    "    summarize(\n",
    "        'fuzzy_25' = (`0.2` + `0.3`)/2,\n",
    "        'fuzzy_50' = (`0.45` + `0.55`)/2,\n",
    "        'fuzzy_75' = (`0.7` + `0.8`)/2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save these fuzzy percentiles to a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to table\n",
    "fuzzy <- weighted_by_gender %>%\n",
    "    summarize(\n",
    "        'fuzzy_25' = (`0.2` + `0.3`)/2,\n",
    "        'fuzzy_50' = (`0.45` + `0.55`)/2,\n",
    "        'fuzzy_75' = (`0.7` + `0.8`)/2,\n",
    "    ) \n",
    "\n",
    "# adding a variable for gender\n",
    "fuzzy$gender <- c(\"Female\", \"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy %>%\n",
    "    write_csv(\"Tables\\\\fuzzy_earnings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for these fuzzy percentiles to pass disclosure review, they require proof that the underlying counts contain at least 10 data points at the individual level and at least 3 data points at the institution level. \n",
    "\n",
    "For example, it is not possible to export a distribution of earnings of female PhD graduates of only 1 university or comparing earning distributions between just 2 universities. The sample should include at least 3 universities, for example, by comparing a group of at least 3 research universities versus a group of at least 3 teaching universities.\n",
    "\n",
    "In the SQL query above, the data on individuals (`refid`) and institutions (`sdrincd`) has already been pulled, so it can be used to find the counts of distinct individuals and institutions.\n",
    "\n",
    "> Individual and institutional counts provided as corresponding proof must be unweighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save individual and institution counts\n",
    "counts_for_earnings <- earnings %>%\n",
    "    group_by(gender) %>%\n",
    "    summarize(\n",
    "        count_individuals = n_distinct(refid),\n",
    "        count_institutions = n_distinct(sdrincd),\n",
    "        count_weighted_individuals = sum(wtsurvy)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_for_earnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can now be used as proof that the fuzzy percentiles are based on counts that pass the disclosure thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as counts_for_earnings.csv\n",
    "counts_for_earnings %>%\n",
    "    write_csv(\"Tables\\\\counts_for_earnings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we look at the best ways to export our presentation-ready plots. We use ``ggsave`` to save our plots in a png, jpeg and pdf format without losing quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PNG\n",
    "\n",
    "First, we provide an example of using ``ggsave`` with two parameters: `filename` and `plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggsave(filename = \"Figures\\\\bar_plot_prob.png\", # saving path\n",
    "       plot = bar_plot # plot name\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might not be the preferred way of saving a plot as the dimensions of the plot default to 6.67 x 6.67. We suggest looking at this file we just saved in its respective path. You will see how all the labels are cluttered and the graph can not be interpretted. Thus, we recommend using the `width` and `height` parameters in addition to `filename` and `plot`. We provide examples to save our bar plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggsave(filename = \"Figures\\\\bar_plot.png\", # saving path\n",
    "       plot = bar_plot,  # plot name\n",
    "       width = 20, # width\n",
    "       height = 12 # height\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above saves the plots in a format that can be interpretted conveniently. We reuse this code to save in a JPEG and PDF format below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggsave(filename = \"Figures\\\\bar_plot.jpeg\", # saving path\n",
    "       plot = bar_plot,  # plot name\n",
    "       width = 20, # width\n",
    "       height = 12 # height\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggsave(filename = \"Figures\\\\bar_plot.pdf\", # saving path\n",
    "       plot = bar_plot,  # plot name\n",
    "       width = 20, # width\n",
    "       height = 12 # height\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder\n",
    "Every single item for export, regardless of whether it is a .csv, .pdf, .png, or something else, must have corresponding proof in the input file to show that every group used to create this statistic followed the disclosure review rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: After the end of the course, it is possible to export the code that have been used during the class. In order to do that, make your facilitator aware of your group's interest and they will handle it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "dbDisconnect(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
